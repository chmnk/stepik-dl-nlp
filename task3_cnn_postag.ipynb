{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "task3_cnn_postag.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbc6oXwZks0F"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5K035b0nqWR"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KtOwtunntwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712a7e23-e187-4036-e1f7-bc7d5e3a97be"
      },
      "source": [
        "x = torch.tensor([[1, 1, 0, 0, 1], [0, 1, 0, 1, 0]]).T\n",
        "print(x.shape)\n",
        "krn = torch.tensor([[1, 1, 0], [0, 1, 1]])\n",
        "print(krn.shape)\n",
        "b = 0\n",
        "K = krn.shape[1]\n",
        "n_in, n_ch = x.shape\n",
        "n_out = n_in - K + 1\n",
        "y = torch.zeros(n_out)\n",
        "for pos in range(n_out):\n",
        "    cur_v = 0\n",
        "    for k in range(0, K):\n",
        "        cur_v += torch.dot(x[pos + k], krn[:, k])\n",
        "    y[pos] = b + cur_v\n",
        "    \n",
        "krn = torch.tensor([[[1, 1, 0], [0, 1, 1]], [[1, 0, 0], [0, 0, 1]]])\n",
        "print(krn.shape)\n",
        "K1, K = krn.shape[0], krn.shape[2]\n",
        "n_in, n_ch = x.shape\n",
        "n_out = n_in - K + 1\n",
        "y = torch.zeros((n_out, K1))\n",
        "b = torch.zeros(K1)\n",
        "for pos in range(n_out):\n",
        "    cur_v = torch.tensordot(x[pos : pos + K, :], krn, dims=([0, 1], [2, 1]))\n",
        "    y[pos] = b + cur_v\n",
        "print(y.numpy())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 2, 3])\n",
            "[[3. 1.]\n",
            " [2. 2.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQCXyl2Saa5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486e0ef9-a121-4ed2-e76b-2e024f6aef2b"
      },
      "source": [
        "a = torch.tensor([1.,2.,3.])\n",
        "b = torch.tensor([[-1.,-2.,-3.], [0.1, 0.2, 0.1]]).T\n",
        "print(torch.mm(torch.unsqueeze(a, 0), b))\n",
        "print(torch.dot(a, b[:, 0]))\n",
        "print(torch.dot(a, b[:, 1]))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-14.0000,   0.8000]])\n",
            "tensor(-14.)\n",
            "tensor(0.8000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws4Hrp4RjTQ7"
      },
      "source": [
        "# Свёрточные нейросети и POS-теггинг\n",
        "\n",
        "POS-теггинг - определение частей речи (снятие частеречной неоднозначности)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmocnesQ4U6r"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bTZv5X9jTRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be94132b-2464-4e16-f8af-a27e0e1b3ea6"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
        "import sys; sys.path.append('./stepik-dl-nlp')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'stepik-dl-nlp' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:42:57.976431Z",
          "start_time": "2019-10-29T19:42:57.959538Z"
        },
        "id": "j629aoU5jTRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8233b342-af52-43f5-a5a7-488289429b44"
      },
      "source": [
        "!pip install pyconll\n",
        "!pip install spacy_udpipe"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyconll in /usr/local/lib/python3.7/dist-packages (3.0.4)\n",
            "Requirement already satisfied: spacy_udpipe in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ufal.udpipe>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy_udpipe) (1.2.0.3)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy_udpipe) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (56.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.1.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_udpipe) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_udpipe) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:34.549739Z",
          "start_time": "2019-10-29T19:49:32.179692Z"
        },
        "id": "4P05ohGljTRU"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pyconll\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "import dlnlputils\n",
        "from dlnlputils.data import tokenize_corpus, build_vocabulary, \\\n",
        "    character_tokenize, pos_corpus_to_tensor, POSTagger\n",
        "from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
        "from google.colab import files\n",
        "\n",
        "import gc\n",
        "\n",
        "init_random_seed()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_z2s_SVjTRV"
      },
      "source": [
        "### Загрузка текстов и разбиение на обучающую и тестовую подвыборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:08.433599Z",
          "start_time": "2019-10-29T19:46:05.110693Z"
        },
        "id": "ES_3qyxMjTRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460930a6-fb96-4bbd-8817-5387056e7e10"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "!wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
        "!wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-26 12:15:49--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81043533 (77M) [text/plain]\n",
            "Saving to: ‘./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu’\n",
            "\n",
            "./stepik-dl-nlp/dat 100%[===================>]  77.29M   348MB/s    in 0.2s    \n",
            "\n",
            "2021-04-26 12:15:52 (348 MB/s) - ‘./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu’ saved [81043533/81043533]\n",
            "\n",
            "--2021-04-26 12:15:52--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10903424 (10M) [text/plain]\n",
            "Saving to: ‘./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu’\n",
            "\n",
            "./stepik-dl-nlp/dat 100%[===================>]  10.40M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-04-26 12:15:52 (161 MB/s) - ‘./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu’ saved [10903424/10903424]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:56.525561Z",
          "start_time": "2019-10-29T19:49:37.315213Z"
        },
        "id": "CqX_0_aEjTRZ"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "full_train = pyconll.load_from_file('./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu')\n",
        "full_test = pyconll.load_from_file('./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:56.548127Z",
          "start_time": "2019-10-29T19:49:56.527559Z"
        },
        "id": "f1rSAl9UjTRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20dc7e69-3316-443c-8a77-15cd5dc67b19"
      },
      "source": [
        "for sent in full_train[:2]:\n",
        "    for token in sent:\n",
        "        print(token.form, token.upos)\n",
        "    print()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Анкета NOUN\n",
            ". PUNCT\n",
            "\n",
            "Начальник NOUN\n",
            "областного ADJ\n",
            "управления NOUN\n",
            "связи NOUN\n",
            "Семен PROPN\n",
            "Еремеевич PROPN\n",
            "был AUX\n",
            "человек NOUN\n",
            "простой ADJ\n",
            ", PUNCT\n",
            "приходил VERB\n",
            "на ADP\n",
            "работу NOUN\n",
            "всегда ADV\n",
            "вовремя ADV\n",
            ", PUNCT\n",
            "здоровался VERB\n",
            "с ADP\n",
            "секретаршей NOUN\n",
            "за ADP\n",
            "руку NOUN\n",
            "и CCONJ\n",
            "иногда ADV\n",
            "даже PART\n",
            "писал VERB\n",
            "в ADP\n",
            "стенгазету NOUN\n",
            "заметки NOUN\n",
            "под ADP\n",
            "псевдонимом NOUN\n",
            "\" PUNCT\n",
            "Муха NOUN\n",
            "\" PUNCT\n",
            ". PUNCT\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:56.916262Z",
          "start_time": "2019-10-29T19:49:56.549806Z"
        },
        "id": "AEg6xARQjTRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6891be-048f-46ff-d575-6cec14429765"
      },
      "source": [
        "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
        "MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n",
        "print('Наибольшая длина предложения', MAX_SENT_LEN)\n",
        "print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Наибольшая длина предложения 205\n",
            "Наибольшая длина токена 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:57.251433Z",
          "start_time": "2019-10-29T19:49:56.919818Z"
        },
        "id": "MEtzeOnijTRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b13de5b-6dea-4301-b224-59fadffa338d"
      },
      "source": [
        "all_train_texts = [' '.join(token.form for token in sent) for sent in full_train]\n",
        "print('\\n'.join(all_train_texts[:10]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Анкета .\n",
            "Начальник областного управления связи Семен Еремеевич был человек простой , приходил на работу всегда вовремя , здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом \" Муха \" .\n",
            "В приемной его с утра ожидали посетители , - кое-кто с важными делами , а кое-кто и с такими , которые легко можно было решить в нижестоящих инстанциях , не затрудняя Семена Еремеевича .\n",
            "Однако стиль работы Семена Еремеевича заключался в том , чтобы принимать всех желающих и лично вникать в дело .\n",
            "Приемная была обставлена просто , но по-деловому .\n",
            "У двери стоял стол секретарши , на столе - пишущая машинка с широкой кареткой .\n",
            "В углу висел репродуктор и играло радио для развлечения ожидающих и еще для того , чтобы заглушать голос начальника , доносившийся из кабинета , так как , бесспорно , среди посетителей могли находиться и случайные люди .\n",
            "Кабинет отличался скромностью , присущей Семену Еремеевичу .\n",
            "В глубине стоял широкий письменный стол с бронзовыми чернильницами и перед ним два кожаных кресла .\n",
            "Справа был стол для заседаний - длинный , накрытый зеленым сукном и с обеих сторон аккуратно заставленный стульями .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.124148Z",
          "start_time": "2019-10-29T19:49:57.254191Z"
        },
        "id": "R5_E9U0VjTRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a715f7a5-811e-4df0-c5fc-6ebe4107a5ca"
      },
      "source": [
        "train_char_tokenized = tokenize_corpus(all_train_texts, tokenizer=character_tokenize)\n",
        "char_vocab, word_doc_freq = build_vocabulary(train_char_tokenized, max_doc_freq=1.0, min_count=5, pad_word='<PAD>')\n",
        "print(\"Количество уникальных символов\", len(char_vocab))\n",
        "print(list(char_vocab.items())[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество уникальных символов 150\n",
            "[('<PAD>', 0), (' ', 1), ('о', 2), ('е', 3), ('а', 4), ('т', 5), ('и', 6), ('н', 7), ('.', 8), ('с', 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.524125Z",
          "start_time": "2019-10-29T19:49:58.125577Z"
        },
        "id": "pCjVOlc4jTRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7a0b08-bad8-45b2-b104-2f2b20dd09fd"
      },
      "source": [
        "UNIQUE_TAGS = ['<NOTAG>'] + sorted({token.upos for sent in full_train for token in sent if token.upos})\n",
        "label2id = {label: i for i, label in enumerate(UNIQUE_TAGS)}\n",
        "label2id"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<NOTAG>': 0,\n",
              " 'ADJ': 1,\n",
              " 'ADP': 2,\n",
              " 'ADV': 3,\n",
              " 'AUX': 4,\n",
              " 'CCONJ': 5,\n",
              " 'DET': 6,\n",
              " 'INTJ': 7,\n",
              " 'NOUN': 8,\n",
              " 'NUM': 9,\n",
              " 'PART': 10,\n",
              " 'PRON': 11,\n",
              " 'PROPN': 12,\n",
              " 'PUNCT': 13,\n",
              " 'SCONJ': 14,\n",
              " 'SYM': 15,\n",
              " 'VERB': 16,\n",
              " 'X': 17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.752672Z",
          "start_time": "2019-10-29T19:49:58.526431Z"
        },
        "id": "ph_C8YLajTRi"
      },
      "source": [
        "train_inputs, train_labels = pos_corpus_to_tensor(full_train, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n",
        "train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "\n",
        "test_inputs, test_labels = pos_corpus_to_tensor(full_test, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n",
        "test_dataset = TensorDataset(test_inputs, test_labels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqmx3mpsIRCy",
        "outputId": "9081b1ae-f0bc-4ba3-a455-7c3cc0f335a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "del full_train\n",
        "del full_test\n",
        "gc.collect()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.754883Z",
          "start_time": "2019-10-29T19:49:40.582Z"
        },
        "scrolled": true,
        "id": "UxbOQkFnjTRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d060d50-4b0f-414a-8826-4ab8ab2af82d"
      },
      "source": [
        "train_inputs[1][:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 39,  4, 25,  4, 11, 20,  7,  6, 13,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  2, 23, 11,  4,  9,  5,  7,  2, 22,  2,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0, 17, 16, 10,  4, 12, 11,  3,  7,  6, 19,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  9, 12, 19, 21,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0, 40,  3, 15,  3,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.756496Z",
          "start_time": "2019-10-29T19:49:40.711Z"
        },
        "id": "mG64dqaYjTRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f584d56e-d950-40de-8cf4-8877ac4605b6"
      },
      "source": [
        "train_labels[1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8,  1,  8,  8, 12, 12,  4,  8,  1, 13, 16,  2,  8,  3,  3, 13, 16,  2,\n",
              "         8,  2,  8,  5,  3, 10, 16,  2,  8,  8,  2,  8, 13,  8, 13, 13,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvOzdQXJ4dw2"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42OXu3MWjTRl"
      },
      "source": [
        "### Вспомогательная свёрточная архитектура"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.316516Z",
          "start_time": "2019-10-29T19:46:17.539Z"
        },
        "id": "hJNI-fP9jTRm"
      },
      "source": [
        "class StackedConv1d(nn.Module):\n",
        "    def __init__(self, features_num, layers_n=1, kernel_size=3, conv_layer=nn.Conv1d, dropout=0.0, do_dilation=False):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        dilation = 1\n",
        "        for l_id in range(layers_n):\n",
        "            if not do_dilation:\n",
        "                dilation = int(2**l_id)\n",
        "            layers.append(nn.Sequential(\n",
        "                conv_layer(features_num, features_num, kernel_size, padding=kernel_size//2 + dilation - 1, dilation=dilation),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.LeakyReLU()))\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"x - BatchSize x FeaturesNum x SequenceLen\"\"\"\n",
        "        for layer in self.layers:\n",
        "            x = x + layer(x)\n",
        "        return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y3r1btLjTRm"
      },
      "source": [
        "### Предсказание частей речи на уровне отдельных токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.317452Z",
          "start_time": "2019-10-29T19:46:23.135Z"
        },
        "id": "XxEFUU7GjTRm"
      },
      "source": [
        "class SingleTokenPOSTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n",
        "        super().__init__()\n",
        "        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.backbone = StackedConv1d(embedding_size, **kwargs)\n",
        "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.out = nn.Linear(embedding_size, labels_num)\n",
        "        self.labels_num = labels_num\n",
        "    \n",
        "    def forward(self, tokens):\n",
        "        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n",
        "        batch_size, max_sent_len, max_token_len = tokens.shape\n",
        "        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n",
        "        \n",
        "        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n",
        "        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n",
        "        \n",
        "        features = self.backbone(char_embeddings)\n",
        "        \n",
        "        global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n",
        "        \n",
        "        logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n",
        "        logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n",
        "        logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n",
        "        return logits"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.318497Z",
          "start_time": "2019-10-29T19:46:23.764Z"
        },
        "id": "viW36op0jTRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c1bea4-0d6b-470b-8607-696086e20452"
      },
      "source": [
        "single_token_model = SingleTokenPOSTagger(len(char_vocab), len(label2id), embedding_size=64, layers_n=3, kernel_size=3, dropout=0.3, do_dilation=False)\n",
        "print('Количество параметров', sum(np.product(t.shape) for t in single_token_model.parameters()))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество параметров 47826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TxF2lgt4L-l"
      },
      "source": [
        "del best_single_token_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.319470Z",
          "start_time": "2019-10-29T19:46:25.552Z"
        },
        "scrolled": false,
        "id": "zUB64i8jjTRp"
      },
      "source": [
        "(best_val_loss,\n",
        " best_single_token_model) = train_eval_loop(single_token_model,\n",
        "                                            train_dataset,\n",
        "                                            test_dataset,\n",
        "                                            F.cross_entropy,\n",
        "                                            lr=5e-3,\n",
        "                                            epoch_n=7,\n",
        "                                            batch_size=64,\n",
        "                                            device='cuda',\n",
        "                                            early_stopping_patience=5,\n",
        "                                            max_batches_per_epoch_train=500,\n",
        "                                            max_batches_per_epoch_val=100,\n",
        "                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n",
        "                                                                                                                       factor=0.5,\n",
        "                                                                                                                       verbose=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.320568Z",
          "start_time": "2019-10-29T19:46:47.579Z"
        },
        "id": "4MYTMX5JjTRq"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "torch.save(best_single_token_model.state_dict(), './stepik-dl-nlp/models/single_token_pos.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.321566Z",
          "start_time": "2019-10-29T19:46:47.731Z"
        },
        "id": "WSpNmLy4jTRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2c0e15-9912-4525-a024-d16b5983328d"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "single_token_model.load_state_dict(torch.load('./stepik-dl-nlp/models/single_token_pos.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98HvMoAq82AZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271235b6-f818-4e97-fb93-be80c21fbb40"
      },
      "source": [
        "# single_token_model.load_state_dict(best_single_token_model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xIfv59h0mJAW",
        "outputId": "1c161e84-36fa-4f26-c52f-1db2f55606db"
      },
      "source": [
        "\n",
        "\n",
        "files.download( \"./stepik-dl-nlp/models/single_token_pos.pth\" ) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_36a6e395-dd2f-4e3f-bddb-ddf9bb25cb15\", \"single_token_pos.pth\", 195136)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTiFd-Xjo2mx",
        "outputId": "de7e1555-5c43-4b73-d124-57e028f711ae"
      },
      "source": [
        "# del full_train\n",
        "# del full_test\n",
        "# del single_token_model\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q453vu989m_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a0141f-8154-47e7-c61a-3fcbbbefa7e0"
      },
      "source": [
        "train_pred = predict_with_model(single_token_model, train_dataset)\n",
        "train_loss = F.cross_entropy(torch.tensor(train_pred),\n",
        "                             torch.tensor(train_labels))\n",
        "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n",
        "print()\n",
        "\n",
        "test_pred = predict_with_model(single_token_model, test_dataset)\n",
        "test_loss = F.cross_entropy(torch.tensor(test_pred),\n",
        "                            torch.tensor(test_labels))\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1526it [00:35, 42.97it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на обучении 0.016306739300489426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 3/205.75 [00:00<00:06, 29.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   9136391\n",
            "         ADJ       0.88      0.93      0.91     85589\n",
            "         ADP       1.00      0.99      0.99     81963\n",
            "         ADV       0.83      0.90      0.86     44101\n",
            "         AUX       0.85      0.89      0.87      7522\n",
            "       CCONJ       0.87      1.00      0.93     30432\n",
            "         DET       0.90      0.76      0.82     21968\n",
            "        INTJ       0.00      0.00      0.00        78\n",
            "        NOUN       0.97      0.93      0.95    214497\n",
            "         NUM       0.95      0.94      0.95     13746\n",
            "        PART       0.98      0.76      0.86     26651\n",
            "        PRON       0.85      0.92      0.88     38438\n",
            "       PROPN       0.82      0.94      0.88     32401\n",
            "       PUNCT       1.00      1.00      1.00    157989\n",
            "       SCONJ       0.86      0.64      0.73     16219\n",
            "         SYM       1.00      0.99      1.00       840\n",
            "        VERB       0.93      0.95      0.94     97670\n",
            "           X       0.93      0.58      0.72       375\n",
            "\n",
            "    accuracy                           0.99  10006870\n",
            "   macro avg       0.87      0.84      0.85  10006870\n",
            "weighted avg       0.99      0.99      0.99  10006870\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 206/205.75 [00:04<00:00, 43.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на валидации 0.018367711454629898\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   1231232\n",
            "         ADJ       0.88      0.93      0.91     11222\n",
            "         ADP       1.00      0.99      0.99     10585\n",
            "         ADV       0.83      0.90      0.86      6165\n",
            "         AUX       0.84      0.88      0.86      1106\n",
            "       CCONJ       0.87      1.00      0.93      4410\n",
            "         DET       0.89      0.73      0.80      3085\n",
            "        INTJ       0.00      0.00      0.00        11\n",
            "        NOUN       0.97      0.93      0.95     27974\n",
            "         NUM       0.94      0.93      0.94      1829\n",
            "        PART       0.99      0.76      0.86      3877\n",
            "        PRON       0.84      0.92      0.88      5598\n",
            "       PROPN       0.81      0.93      0.87      4438\n",
            "       PUNCT       1.00      1.00      1.00     22694\n",
            "       SCONJ       0.84      0.62      0.72      2258\n",
            "         SYM       1.00      0.98      0.99        53\n",
            "        VERB       0.92      0.95      0.93     13078\n",
            "           X       0.96      0.72      0.83       105\n",
            "\n",
            "    accuracy                           0.99   1349720\n",
            "   macro avg       0.87      0.84      0.85   1349720\n",
            "weighted avg       0.99      0.99      0.99   1349720\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9N3YZwDjTRs"
      },
      "source": [
        "### Предсказание частей речи на уровне предложений (с учётом контекста)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.325744Z",
          "start_time": "2019-10-29T19:46:50.139Z"
        },
        "id": "wVTpEXtSjTRt"
      },
      "source": [
        "class SentenceLevelPOSTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, labels_num, embedding_size=32, single_backbone_kwargs={}, context_backbone_kwargs={}):\n",
        "        super().__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.single_token_backbone = StackedConv1d(embedding_size, **single_backbone_kwargs)\n",
        "        self.context_backbone = StackedConv1d(embedding_size, **context_backbone_kwargs)\n",
        "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.out = nn.Conv1d(embedding_size, labels_num, 1)\n",
        "        self.labels_num = labels_num\n",
        "    \n",
        "    def forward(self, tokens):\n",
        "        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n",
        "        batch_size, max_sent_len, max_token_len = tokens.shape\n",
        "        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n",
        "        \n",
        "        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n",
        "        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n",
        "        char_features = self.single_token_backbone(char_embeddings)\n",
        "        \n",
        "        token_features_flat = self.global_pooling(char_features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n",
        "\n",
        "        token_features = token_features_flat.view(batch_size, max_sent_len, self.embedding_size)  # BatchSize x MaxSentenceLen x EmbSize\n",
        "        token_features = token_features.permute(0, 2, 1)  # BatchSize x EmbSize x MaxSentenceLen\n",
        "        context_features = self.context_backbone(token_features)  # BatchSize x EmbSize x MaxSentenceLen\n",
        "\n",
        "        logits = self.out(context_features)  # BatchSize x LabelsNum x MaxSentenceLen\n",
        "        return logits"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.326925Z",
          "start_time": "2019-10-29T19:46:50.310Z"
        },
        "id": "PDzFUGaKjTRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafe53d4-d8d9-4c6f-8dfa-7e0789658feb"
      },
      "source": [
        "sentence_level_model = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n",
        "                                              single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3),\n",
        "                                              context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, do_dilation=True))\n",
        "print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model.parameters()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество параметров 84882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.327888Z",
          "start_time": "2019-10-29T19:46:50.737Z"
        },
        "scrolled": false,
        "id": "Pq3WyBdnjTRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543e9d0c-efa4-42f1-dff4-d3efd995e998"
      },
      "source": [
        "(best_val_loss,\n",
        " best_sentence_level_model) = train_eval_loop(sentence_level_model,\n",
        "                                              train_dataset,\n",
        "                                              test_dataset,\n",
        "                                              F.cross_entropy,\n",
        "                                              lr=5e-3,\n",
        "                                              epoch_n=10,\n",
        "                                              batch_size=64,\n",
        "                                              device='cuda',\n",
        "                                              early_stopping_patience=5,\n",
        "                                              max_batches_per_epoch_train=500,\n",
        "                                              max_batches_per_epoch_val=100,\n",
        "                                              lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n",
        "                                                                                                                         factor=0.5,\n",
        "                                                                                                                         verbose=True))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Эпоха 0\n",
            "Досрочно остановлено пользователем\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djOlVDs13-DW"
      },
      "source": [
        "cur_model_name "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:16.542052Z",
          "start_time": "2019-08-29T13:56:16.529110Z"
        },
        "id": "wMzISXKejTRv"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "torch.save(best_sentence_level_model.state_dict(), './stepik-dl-nlp/models/sentence_level_pos.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:16.564926Z",
          "start_time": "2019-08-29T13:56:16.544481Z"
        },
        "id": "hAHhWiEqjTRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fb8dca-6518-476e-e888-965b7e970cf1"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "sentence_level_model.load_state_dict(torch.load('./stepik-dl-nlp/models/sentence_level_pos.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xe4b6_T4PrR"
      },
      "source": [
        "del best_sentence_level_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.092139Z",
          "start_time": "2019-08-29T13:56:16.567242Z"
        },
        "id": "yoBANl9ujTRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be3d704-9158-4af1-f91f-10670f5b3f93"
      },
      "source": [
        "train_pred = predict_with_model(sentence_level_model, train_dataset)\n",
        "train_loss = F.cross_entropy(torch.tensor(train_pred),\n",
        "                             torch.tensor(train_labels))\n",
        "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n",
        "print()\n",
        "\n",
        "test_pred = predict_with_model(sentence_level_model, test_dataset)\n",
        "test_loss = F.cross_entropy(torch.tensor(test_pred),\n",
        "                            torch.tensor(test_labels))\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1526it [00:35, 42.63it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на обучении 0.010324694216251373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 3/205.75 [00:00<00:07, 28.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   9136391\n",
            "         ADJ       0.93      0.94      0.93     85589\n",
            "         ADP       1.00      1.00      1.00     81963\n",
            "         ADV       0.86      0.95      0.91     44101\n",
            "         AUX       0.90      0.90      0.90      7522\n",
            "       CCONJ       0.94      0.99      0.96     30432\n",
            "         DET       0.92      0.91      0.92     21968\n",
            "        INTJ       0.58      0.38      0.46        78\n",
            "        NOUN       0.98      0.96      0.97    214497\n",
            "         NUM       0.97      0.92      0.95     13746\n",
            "        PART       0.98      0.86      0.91     26651\n",
            "        PRON       0.92      0.94      0.93     38438\n",
            "       PROPN       0.90      0.97      0.94     32401\n",
            "       PUNCT       1.00      1.00      1.00    157989\n",
            "       SCONJ       0.91      0.84      0.88     16219\n",
            "         SYM       1.00      1.00      1.00       840\n",
            "        VERB       0.95      0.96      0.96     97670\n",
            "           X       0.97      0.52      0.68       375\n",
            "\n",
            "    accuracy                           1.00  10006870\n",
            "   macro avg       0.93      0.89      0.90  10006870\n",
            "weighted avg       1.00      1.00      1.00  10006870\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 206/205.75 [00:04<00:00, 42.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на валидации 0.011435320600867271\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   1231232\n",
            "         ADJ       0.93      0.93      0.93     11222\n",
            "         ADP       1.00      0.99      1.00     10585\n",
            "         ADV       0.86      0.95      0.90      6165\n",
            "         AUX       0.88      0.89      0.88      1106\n",
            "       CCONJ       0.94      0.99      0.96      4410\n",
            "         DET       0.91      0.90      0.90      3085\n",
            "        INTJ       0.57      0.36      0.44        11\n",
            "        NOUN       0.98      0.95      0.97     27974\n",
            "         NUM       0.96      0.90      0.93      1829\n",
            "        PART       0.98      0.86      0.92      3877\n",
            "        PRON       0.92      0.94      0.93      5598\n",
            "       PROPN       0.89      0.97      0.93      4438\n",
            "       PUNCT       1.00      1.00      1.00     22694\n",
            "       SCONJ       0.90      0.83      0.86      2258\n",
            "         SYM       1.00      1.00      1.00        53\n",
            "        VERB       0.94      0.96      0.95     13078\n",
            "           X       0.99      0.65      0.78       105\n",
            "\n",
            "    accuracy                           1.00   1349720\n",
            "   macro avg       0.92      0.89      0.90   1349720\n",
            "weighted avg       1.00      1.00      1.00   1349720\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "suGtk8Ky1Jk2",
        "outputId": "3464ff0e-d62b-453a-dafe-3d948c47e836"
      },
      "source": [
        "\n",
        "files.download( \"./stepik-dl-nlp/models/sentence_level_pos.pth\" ) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1ebbb5c2-ec51-4a4e-9031-ed40b7fd6806\", \"sentence_level_pos.pth\", 346102)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsAFAFq6jTRy"
      },
      "source": [
        "## Применение полученных теггеров и сравнение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.105418Z",
          "start_time": "2019-08-29T13:56:42.093744Z"
        },
        "id": "VUZrokx7jTRy"
      },
      "source": [
        "single_token_pos_tagger = POSTagger(single_token_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n",
        "sentence_level_pos_tagger = POSTagger(sentence_level_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.125540Z",
          "start_time": "2019-08-29T13:56:42.106771Z"
        },
        "id": "8Ce7ELP2jTRz"
      },
      "source": [
        "test_sentences = [\n",
        "    'Мама мыла раму.',\n",
        "    'Косил косой косой косой.',\n",
        "    'Глокая куздра штеко будланула бокра и куздрячит бокрёнка.',\n",
        "    'Сяпала Калуша с Калушатами по напушке.',\n",
        "    'Пирожки поставлены в печь, мама любит печь.',\n",
        "    'Ведро дало течь, вода стала течь.',\n",
        "    'Три да три, будет дырка.',\n",
        "    'Три да три, будет шесть.',\n",
        "    'Сорок сорок'\n",
        "]\n",
        "test_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.148124Z",
          "start_time": "2019-08-29T13:56:42.126930Z"
        },
        "id": "L5ohjHwWjTR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb512af5-cd97-4a37-b03f-0f0bf4f2b4b7"
      },
      "source": [
        "for sent_tokens, sent_tags in zip(test_sentences_tokenized, single_token_pos_tagger(test_sentences)):\n",
        "    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1it [00:00, 72.03it/s]                     "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "мама-NOUN мыла-VERB раму-NOUN\n",
            "\n",
            "косил-VERB косой-ADJ косой-ADJ косой-ADJ\n",
            "\n",
            "глокая-ADJ куздра-NOUN штеко-ADJ будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN\n",
            "\n",
            "сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN\n",
            "\n",
            "пирожки-NOUN поставлены-VERB в-ADP печь-VERB мама-NOUN любит-VERB печь-VERB\n",
            "\n",
            "ведро-ADV дало-VERB течь-VERB вода-NOUN стала-VERB течь-VERB\n",
            "\n",
            "три-NUM да-NOUN три-NUM будет-VERB дырка-NOUN\n",
            "\n",
            "три-NUM да-NOUN три-NUM будет-VERB шесть-NUM\n",
            "\n",
            "сорок-NOUN сорок-NOUN\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.168810Z",
          "start_time": "2019-08-29T13:56:42.149698Z"
        },
        "id": "DJQTm8gajTR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6caa60f6-3590-41d7-d956-fbc89c8836aa"
      },
      "source": [
        "for sent_tokens, sent_tags in zip(test_sentences_tokenized, sentence_level_pos_tagger(test_sentences)):\n",
        "    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1it [00:00, 80.50it/s]                     "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "мама-NOUN мыла-VERB раму-NOUN\n",
            "\n",
            "косил-VERB косой-NOUN косой-NOUN косой-NOUN\n",
            "\n",
            "глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN\n",
            "\n",
            "сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN\n",
            "\n",
            "пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-VERB\n",
            "\n",
            "ведро-NOUN дало-VERB течь-NOUN вода-NOUN стала-VERB течь-NOUN\n",
            "\n",
            "три-NUM да-CCONJ три-NUM будет-AUX дырка-NOUN\n",
            "\n",
            "три-NUM да-CCONJ три-NUM будет-AUX шесть-NUM\n",
            "\n",
            "сорок-NOUN сорок-NOUN\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWgDuruKjTR0"
      },
      "source": [
        "## Свёрточный модуль своими руками"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.193140Z",
          "start_time": "2019-08-29T13:56:42.170233Z"
        },
        "id": "3KujWJy3jTR1"
      },
      "source": [
        "class MyConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = padding\n",
        "        self.weight = nn.Parameter(torch.randn(in_channels * kernel_size, out_channels) / (in_channels * kernel_size),\n",
        "                                   requires_grad=True)\n",
        "        self.bias = nn.Parameter(torch.zeros(out_channels), requires_grad=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"x - BatchSize x InChannels x SequenceLen\"\"\"\n",
        "\n",
        "        batch_size, src_channels, sequence_len = x.shape        \n",
        "        if self.padding > 0:\n",
        "            pad = x.new_zeros(batch_size, src_channels, self.padding)\n",
        "            x = torch.cat((pad, x, pad), dim=-1)\n",
        "            sequence_len = x.shape[-1]\n",
        "\n",
        "        chunks = []\n",
        "        chunk_size = sequence_len - self.kernel_size + 1\n",
        "        for offset in range(self.kernel_size):\n",
        "            chunks.append(x[:, :, offset:offset + chunk_size])\n",
        "\n",
        "        in_features = torch.cat(chunks, dim=1)  # BatchSize x InChannels * KernelSize x ChunkSize\n",
        "        in_features = in_features.permute(0, 2, 1)  # BatchSize x ChunkSize x InChannels * KernelSize\n",
        "        out_features = torch.bmm(in_features, self.weight.unsqueeze(0).expand(batch_size, -1, -1)) + self.bias.unsqueeze(0).unsqueeze(0)\n",
        "        out_features = out_features.permute(0, 2, 1)  # BatchSize x OutChannels x ChunkSize\n",
        "        return out_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.210013Z",
          "start_time": "2019-08-29T13:56:42.194620Z"
        },
        "id": "eKEeQjU9jTR2"
      },
      "source": [
        "sentence_level_model_my_conv = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n",
        "                                                      single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d),\n",
        "                                                      context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d))\n",
        "print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model_my_conv.parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T14:06:00.233326Z",
          "start_time": "2019-08-29T13:56:42.211456Z"
        },
        "id": "1pF421DOjTR2"
      },
      "source": [
        "(best_val_loss,\n",
        " best_sentence_level_model_my_conv) = train_eval_loop(sentence_level_model_my_conv,\n",
        "                                                      train_dataset,\n",
        "                                                      test_dataset,\n",
        "                                                      F.cross_entropy,\n",
        "                                                      lr=5e-3,\n",
        "                                                      epoch_n=10,\n",
        "                                                      batch_size=64,\n",
        "                                                      device='cuda',\n",
        "                                                      early_stopping_patience=5,\n",
        "                                                      max_batches_per_epoch_train=500,\n",
        "                                                      max_batches_per_epoch_val=100,\n",
        "                                                      lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n",
        "                                                                                                                                 factor=0.5,\n",
        "                                                                                                                                 verbose=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T14:06:39.145214Z",
          "start_time": "2019-08-29T14:06:00.234936Z"
        },
        "id": "lW76zLsNjTR2"
      },
      "source": [
        "train_pred = predict_with_model(best_sentence_level_model_my_conv, train_dataset)\n",
        "train_loss = F.cross_entropy(torch.tensor(train_pred),\n",
        "                             torch.tensor(train_labels))\n",
        "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n",
        "print()\n",
        "\n",
        "test_pred = predict_with_model(best_sentence_level_model_my_conv, test_dataset)\n",
        "test_loss = F.cross_entropy(torch.tensor(test_pred),\n",
        "                            torch.tensor(test_labels))\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0TBG959npFO"
      },
      "source": [
        ""
      ]
    }
  ]
}