{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "task3_cnn_postag.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbc6oXwZks0F"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5K035b0nqWR"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KtOwtunntwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38992f87-f532-493d-e242-a7bdd2fcf244"
      },
      "source": [
        "x = torch.tensor([[1, 1, 0, 0, 1], [0, 1, 0, 1, 0]]).T\n",
        "print(x.shape)\n",
        "krn = torch.tensor([[1, 1, 0], [0, 1, 1]])\n",
        "print(krn.shape)\n",
        "b = 0\n",
        "K = krn.shape[1]\n",
        "n_in, n_ch = x.shape\n",
        "n_out = n_in - K + 1\n",
        "y = torch.zeros(n_out)\n",
        "for pos in range(n_out):\n",
        "    cur_v = 0\n",
        "    for k in range(0, K):\n",
        "        cur_v += torch.dot(x[pos + k], krn[:, k])\n",
        "    y[pos] = b + cur_v\n",
        "    \n",
        "krn = torch.tensor([[[1, 1, 0], [0, 1, 1]], [[1, 0, 0], [0, 0, 1]]])\n",
        "print(krn.shape)\n",
        "K1, K = krn.shape[0], krn.shape[2]\n",
        "n_in, n_ch = x.shape\n",
        "n_out = n_in - K + 1\n",
        "y = torch.zeros((n_out, K1))\n",
        "b = torch.zeros(K1)\n",
        "for pos in range(n_out):\n",
        "    cur_v = torch.tensordot(x[pos : pos + K, :], krn, dims=([0, 1], [2, 1]))\n",
        "    y[pos] = b + cur_v\n",
        "print(y.numpy())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 2, 3])\n",
            "[[3. 1.]\n",
            " [2. 2.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQCXyl2Saa5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e9743a-11cb-43a4-b084-c81c0b6951ec"
      },
      "source": [
        "a = torch.tensor([1.,2.,3.])\n",
        "b = torch.tensor([[-1.,-2.,-3.], [0.1, 0.2, 0.1]]).T\n",
        "print(torch.mm(torch.unsqueeze(a, 0), b))\n",
        "print(torch.dot(a, b[:, 0]))\n",
        "print(torch.dot(a, b[:, 1]))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-14.0000,   0.8000]])\n",
            "tensor(-14.)\n",
            "tensor(0.8000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws4Hrp4RjTQ7"
      },
      "source": [
        "# Свёрточные нейросети и POS-теггинг\n",
        "\n",
        "POS-теггинг - определение частей речи (снятие частеречной неоднозначности)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmocnesQ4U6r"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bTZv5X9jTRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163656b1-872a-4e83-925c-e1de8b54cd39"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
        "import sys; sys.path.append('./stepik-dl-nlp')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stepik-dl-nlp'...\n",
            "remote: Enumerating objects: 289, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 289 (delta 10), reused 14 (delta 6), pack-reused 266\u001b[K\n",
            "Receiving objects: 100% (289/289), 42.27 MiB | 16.24 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 1)) (0.22.2.post1)\n",
            "Collecting spacy-udpipe\n",
            "  Downloading https://files.pythonhosted.org/packages/16/60/2a985e25f6a398655f018e5e43d16ba3dbd65f0d4d6ae22add90578669a5/spacy_udpipe-0.3.2-py3-none-any.whl\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 4)) (1.8.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 5)) (3.2.2)\n",
            "Collecting ipymarkup\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/9b/bf54c98d50735a4a7c84c71e92c5361730c878ebfe903d2c2d196ef66055/ipymarkup-0.9.0-py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 7)) (4.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 9)) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 10)) (4.41.1)\n",
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/1c/224cdc3d9a32ed706c8fb1f30b491be6ea5da114ff4edc174014cc24fa43/youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 12)) (0.11.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 13)) (4.10.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 14)) (5.5.0)\n",
            "Collecting pyconll\n",
            "  Downloading https://files.pythonhosted.org/packages/60/7f/148a5b6f99b8a22373bfbcafd9d6776278fec14810ae95c4fe37965f6619/pyconll-3.0.4-py3-none-any.whl\n",
            "Collecting gensim==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/93/c6011037f24e3106d13f3be55297bf84ece2bf15b278cc4776339dc52db5/gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 5.6MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Collecting livelossplot==0.5.3\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/08/1884157a3de72d41fa97cacacafaa49abf00eba53cb7e08615b2b65b4a9d/livelossplot-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (1.0.1)\n",
            "Collecting ufal.udpipe>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/72/2b8b9dc7c80017c790bb3308bbad34b57accfed2ac2f1f4ab252ff4e9cb2/ufal.udpipe-1.2.0.3.tar.gz (304kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.2.4)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (0.10.0)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r stepik-dl-nlp/requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome->-r stepik-dl-nlp/requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.0.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.3.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (56.0.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.8.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1->-r stepik-dl-nlp/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1->-r stepik-dl-nlp/requirements.txt (line 16)) (5.0.0)\n",
            "Requirement already satisfied: bokeh; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (2.3.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup->-r stepik-dl-nlp/requirements.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (22.0.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (3.13)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (2.11.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (20.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.10.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.4.1)\n",
            "Building wheels for collected packages: wget, ufal.udpipe, intervaltree\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=06d2b7288d298728de7340b187019c3916632efbd935489f205af37c91953700\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp37-cp37m-linux_x86_64.whl size=5626574 sha256=3db2056d71c16b96458a8e4f7ad5275999e75ca59e45e58ddb5533b8232e9ab8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/9d/db/6d3404c33da5b7adb6c6972853efb6a27649d3ba15f7e9bebb\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26102 sha256=5b5529da99e815992235168603e0d0929d4df62670df06336d1e86b523b62685\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
            "Successfully built wget ufal.udpipe intervaltree\n",
            "Installing collected packages: ufal.udpipe, spacy-udpipe, dawg-python, pymorphy2-dicts-ru, pymorphy2, intervaltree, ipymarkup, youtokentome, pyconll, gensim, wget, livelossplot\n",
            "  Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed dawg-python-0.7.2 gensim-3.8.1 intervaltree-3.1.0 ipymarkup-0.9.0 livelossplot-0.5.3 pyconll-3.0.4 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 spacy-udpipe-0.3.2 ufal.udpipe-1.2.0.3 wget-3.2 youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:42:57.976431Z",
          "start_time": "2019-10-29T19:42:57.959538Z"
        },
        "id": "j629aoU5jTRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b653f960-479d-4def-c329-95c360cebb70"
      },
      "source": [
        "!pip install pyconll\n",
        "!pip install spacy_udpipe"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyconll in /usr/local/lib/python3.7/dist-packages (3.0.4)\n",
            "Requirement already satisfied: spacy_udpipe in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy_udpipe) (2.2.4)\n",
            "Requirement already satisfied: ufal.udpipe>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy_udpipe) (1.2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (56.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_udpipe) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_udpipe) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_udpipe) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy_udpipe) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:34.549739Z",
          "start_time": "2019-10-29T19:49:32.179692Z"
        },
        "id": "4P05ohGljTRU"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pyconll\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "import dlnlputils\n",
        "from dlnlputils.data import tokenize_corpus, build_vocabulary, \\\n",
        "    character_tokenize, pos_corpus_to_tensor, POSTagger\n",
        "from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
        "from google.colab import files\n",
        "\n",
        "import gc\n",
        "\n",
        "init_random_seed()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_z2s_SVjTRV"
      },
      "source": [
        "### Загрузка текстов и разбиение на обучающую и тестовую подвыборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:08.433599Z",
          "start_time": "2019-10-29T19:46:05.110693Z"
        },
        "id": "ES_3qyxMjTRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78049c8d-2266-46b1-d167-612ddfc1128a"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "!wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
        "!wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-26 19:11:23--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81043533 (77M) [text/plain]\n",
            "Saving to: ‘./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu’\n",
            "\n",
            "./stepik-dl-nlp/dat 100%[===================>]  77.29M   115MB/s    in 0.7s    \n",
            "\n",
            "2021-04-26 19:11:25 (115 MB/s) - ‘./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu’ saved [81043533/81043533]\n",
            "\n",
            "--2021-04-26 19:11:25--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10903424 (10M) [text/plain]\n",
            "Saving to: ‘./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu’\n",
            "\n",
            "./stepik-dl-nlp/dat 100%[===================>]  10.40M  36.5MB/s    in 0.3s    \n",
            "\n",
            "2021-04-26 19:11:25 (36.5 MB/s) - ‘./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu’ saved [10903424/10903424]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:56.525561Z",
          "start_time": "2019-10-29T19:49:37.315213Z"
        },
        "id": "CqX_0_aEjTRZ"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "full_train = pyconll.load_from_file('./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu')\n",
        "full_test = pyconll.load_from_file('./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:56.548127Z",
          "start_time": "2019-10-29T19:49:56.527559Z"
        },
        "id": "f1rSAl9UjTRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58a9d11-26c1-4431-f68f-4517ba6d2f6b"
      },
      "source": [
        "for sent in full_train[:2]:\n",
        "    for token in sent:\n",
        "        print(token.form, token.upos)\n",
        "    print()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Анкета NOUN\n",
            ". PUNCT\n",
            "\n",
            "Начальник NOUN\n",
            "областного ADJ\n",
            "управления NOUN\n",
            "связи NOUN\n",
            "Семен PROPN\n",
            "Еремеевич PROPN\n",
            "был AUX\n",
            "человек NOUN\n",
            "простой ADJ\n",
            ", PUNCT\n",
            "приходил VERB\n",
            "на ADP\n",
            "работу NOUN\n",
            "всегда ADV\n",
            "вовремя ADV\n",
            ", PUNCT\n",
            "здоровался VERB\n",
            "с ADP\n",
            "секретаршей NOUN\n",
            "за ADP\n",
            "руку NOUN\n",
            "и CCONJ\n",
            "иногда ADV\n",
            "даже PART\n",
            "писал VERB\n",
            "в ADP\n",
            "стенгазету NOUN\n",
            "заметки NOUN\n",
            "под ADP\n",
            "псевдонимом NOUN\n",
            "\" PUNCT\n",
            "Муха NOUN\n",
            "\" PUNCT\n",
            ". PUNCT\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:56.916262Z",
          "start_time": "2019-10-29T19:49:56.549806Z"
        },
        "id": "AEg6xARQjTRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62df6b03-8a6f-41f9-e6e8-fcc189b2abbb"
      },
      "source": [
        "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
        "MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n",
        "print('Наибольшая длина предложения', MAX_SENT_LEN)\n",
        "print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Наибольшая длина предложения 205\n",
            "Наибольшая длина токена 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:57.251433Z",
          "start_time": "2019-10-29T19:49:56.919818Z"
        },
        "id": "MEtzeOnijTRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c31266c2-2d04-4a3e-ba78-3ada3ac877e0"
      },
      "source": [
        "all_train_texts = [' '.join(token.form for token in sent) for sent in full_train]\n",
        "print('\\n'.join(all_train_texts[:10]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Анкета .\n",
            "Начальник областного управления связи Семен Еремеевич был человек простой , приходил на работу всегда вовремя , здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом \" Муха \" .\n",
            "В приемной его с утра ожидали посетители , - кое-кто с важными делами , а кое-кто и с такими , которые легко можно было решить в нижестоящих инстанциях , не затрудняя Семена Еремеевича .\n",
            "Однако стиль работы Семена Еремеевича заключался в том , чтобы принимать всех желающих и лично вникать в дело .\n",
            "Приемная была обставлена просто , но по-деловому .\n",
            "У двери стоял стол секретарши , на столе - пишущая машинка с широкой кареткой .\n",
            "В углу висел репродуктор и играло радио для развлечения ожидающих и еще для того , чтобы заглушать голос начальника , доносившийся из кабинета , так как , бесспорно , среди посетителей могли находиться и случайные люди .\n",
            "Кабинет отличался скромностью , присущей Семену Еремеевичу .\n",
            "В глубине стоял широкий письменный стол с бронзовыми чернильницами и перед ним два кожаных кресла .\n",
            "Справа был стол для заседаний - длинный , накрытый зеленым сукном и с обеих сторон аккуратно заставленный стульями .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.124148Z",
          "start_time": "2019-10-29T19:49:57.254191Z"
        },
        "id": "R5_E9U0VjTRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f21993-fe64-41de-e3ff-28d91e75b603"
      },
      "source": [
        "train_char_tokenized = tokenize_corpus(all_train_texts, tokenizer=character_tokenize)\n",
        "char_vocab, word_doc_freq = build_vocabulary(train_char_tokenized, max_doc_freq=1.0, min_count=5, pad_word='<PAD>')\n",
        "print(\"Количество уникальных символов\", len(char_vocab))\n",
        "print(list(char_vocab.items())[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество уникальных символов 150\n",
            "[('<PAD>', 0), (' ', 1), ('о', 2), ('е', 3), ('а', 4), ('т', 5), ('и', 6), ('н', 7), ('.', 8), ('с', 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.524125Z",
          "start_time": "2019-10-29T19:49:58.125577Z"
        },
        "id": "pCjVOlc4jTRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fa4185-d4fb-4033-9dc0-8b247270cf75"
      },
      "source": [
        "UNIQUE_TAGS = ['<NOTAG>'] + sorted({token.upos for sent in full_train for token in sent if token.upos})\n",
        "label2id = {label: i for i, label in enumerate(UNIQUE_TAGS)}\n",
        "label2id"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<NOTAG>': 0,\n",
              " 'ADJ': 1,\n",
              " 'ADP': 2,\n",
              " 'ADV': 3,\n",
              " 'AUX': 4,\n",
              " 'CCONJ': 5,\n",
              " 'DET': 6,\n",
              " 'INTJ': 7,\n",
              " 'NOUN': 8,\n",
              " 'NUM': 9,\n",
              " 'PART': 10,\n",
              " 'PRON': 11,\n",
              " 'PROPN': 12,\n",
              " 'PUNCT': 13,\n",
              " 'SCONJ': 14,\n",
              " 'SYM': 15,\n",
              " 'VERB': 16,\n",
              " 'X': 17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.752672Z",
          "start_time": "2019-10-29T19:49:58.526431Z"
        },
        "id": "ph_C8YLajTRi"
      },
      "source": [
        "train_inputs, train_labels = pos_corpus_to_tensor(full_train, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n",
        "train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "\n",
        "test_inputs, test_labels = pos_corpus_to_tensor(full_test, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n",
        "test_dataset = TensorDataset(test_inputs, test_labels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqmx3mpsIRCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94afcb8e-9aaa-4f8b-daef-20b569cc6388"
      },
      "source": [
        "del full_train\n",
        "del full_test\n",
        "gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.754883Z",
          "start_time": "2019-10-29T19:49:40.582Z"
        },
        "scrolled": true,
        "id": "UxbOQkFnjTRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162042a5-ec27-461e-9db7-35912843da3c"
      },
      "source": [
        "train_inputs[1][:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 39,  4, 25,  4, 11, 20,  7,  6, 13,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  2, 23, 11,  4,  9,  5,  7,  2, 22,  2,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0, 17, 16, 10,  4, 12, 11,  3,  7,  6, 19,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  9, 12, 19, 21,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0, 40,  3, 15,  3,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:49:58.756496Z",
          "start_time": "2019-10-29T19:49:40.711Z"
        },
        "id": "mG64dqaYjTRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bfdb8d1-ada5-4c1f-8c7e-7f35086ad86b"
      },
      "source": [
        "train_labels[1]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8,  1,  8,  8, 12, 12,  4,  8,  1, 13, 16,  2,  8,  3,  3, 13, 16,  2,\n",
              "         8,  2,  8,  5,  3, 10, 16,  2,  8,  8,  2,  8, 13,  8, 13, 13,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvOzdQXJ4dw2"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42OXu3MWjTRl"
      },
      "source": [
        "### Вспомогательная свёрточная архитектура"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.316516Z",
          "start_time": "2019-10-29T19:46:17.539Z"
        },
        "id": "hJNI-fP9jTRm"
      },
      "source": [
        "class StackedConv1d(nn.Module):\n",
        "    def __init__(self, features_num, layers_n=1, kernel_size=3, conv_layer=nn.Conv1d, dropout=0.0, do_dilation=False):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        dilation = 1\n",
        "        for l_id in range(layers_n):\n",
        "            if not do_dilation:\n",
        "                dilation = int(2**l_id)\n",
        "            layers.append(nn.Sequential(\n",
        "                conv_layer(features_num, features_num, kernel_size, padding=kernel_size//2 + dilation - 1, dilation=dilation),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.LeakyReLU()))\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"x - BatchSize x FeaturesNum x SequenceLen\"\"\"\n",
        "        for layer in self.layers:\n",
        "            x = x + layer(x)\n",
        "        return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y3r1btLjTRm"
      },
      "source": [
        "### Предсказание частей речи на уровне отдельных токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.317452Z",
          "start_time": "2019-10-29T19:46:23.135Z"
        },
        "id": "XxEFUU7GjTRm"
      },
      "source": [
        "class SingleTokenPOSTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n",
        "        super().__init__()\n",
        "        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.backbone = StackedConv1d(embedding_size, **kwargs)\n",
        "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.out = nn.Linear(embedding_size, labels_num)\n",
        "        self.labels_num = labels_num\n",
        "    \n",
        "    def forward(self, tokens):\n",
        "        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n",
        "        batch_size, max_sent_len, max_token_len = tokens.shape\n",
        "        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n",
        "        \n",
        "        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n",
        "        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n",
        "        \n",
        "        features = self.backbone(char_embeddings)\n",
        "        \n",
        "        global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n",
        "        \n",
        "        logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n",
        "        logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n",
        "        logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n",
        "        return logits"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.318497Z",
          "start_time": "2019-10-29T19:46:23.764Z"
        },
        "id": "viW36op0jTRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4c3012-82b2-4558-e83a-47ec37ce34bb"
      },
      "source": [
        "single_token_model = SingleTokenPOSTagger(len(char_vocab), len(label2id), embedding_size=64, layers_n=3, kernel_size=3, dropout=0.3, do_dilation=False)\n",
        "print('Количество параметров', sum(np.product(t.shape) for t in single_token_model.parameters()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество параметров 47826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TxF2lgt4L-l"
      },
      "source": [
        "del best_single_token_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.319470Z",
          "start_time": "2019-10-29T19:46:25.552Z"
        },
        "scrolled": false,
        "id": "zUB64i8jjTRp"
      },
      "source": [
        "(best_val_loss,\n",
        " best_single_token_model) = train_eval_loop(single_token_model,\n",
        "                                            train_dataset,\n",
        "                                            test_dataset,\n",
        "                                            F.cross_entropy,\n",
        "                                            lr=5e-3,\n",
        "                                            epoch_n=7,\n",
        "                                            batch_size=64,\n",
        "                                            device='cuda',\n",
        "                                            early_stopping_patience=5,\n",
        "                                            max_batches_per_epoch_train=500,\n",
        "                                            max_batches_per_epoch_val=100,\n",
        "                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n",
        "                                                                                                                       factor=0.5,\n",
        "                                                                                                                       verbose=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.320568Z",
          "start_time": "2019-10-29T19:46:47.579Z"
        },
        "id": "4MYTMX5JjTRq"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "torch.save(best_single_token_model.state_dict(), './stepik-dl-nlp/models/single_token_pos.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.321566Z",
          "start_time": "2019-10-29T19:46:47.731Z"
        },
        "id": "WSpNmLy4jTRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2c0e15-9912-4525-a024-d16b5983328d"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "single_token_model.load_state_dict(torch.load('./stepik-dl-nlp/models/single_token_pos.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98HvMoAq82AZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271235b6-f818-4e97-fb93-be80c21fbb40"
      },
      "source": [
        "# single_token_model.load_state_dict(best_single_token_model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xIfv59h0mJAW",
        "outputId": "1c161e84-36fa-4f26-c52f-1db2f55606db"
      },
      "source": [
        "\n",
        "\n",
        "files.download( \"./stepik-dl-nlp/models/single_token_pos.pth\" ) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_36a6e395-dd2f-4e3f-bddb-ddf9bb25cb15\", \"single_token_pos.pth\", 195136)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTiFd-Xjo2mx",
        "outputId": "de7e1555-5c43-4b73-d124-57e028f711ae"
      },
      "source": [
        "# del full_train\n",
        "# del full_test\n",
        "# del single_token_model\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q453vu989m_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a0141f-8154-47e7-c61a-3fcbbbefa7e0"
      },
      "source": [
        "train_pred = predict_with_model(single_token_model, train_dataset)\n",
        "train_loss = F.cross_entropy(torch.tensor(train_pred),\n",
        "                             torch.tensor(train_labels))\n",
        "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n",
        "print()\n",
        "\n",
        "test_pred = predict_with_model(single_token_model, test_dataset)\n",
        "test_loss = F.cross_entropy(torch.tensor(test_pred),\n",
        "                            torch.tensor(test_labels))\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1526it [00:35, 42.97it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на обучении 0.016306739300489426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 3/205.75 [00:00<00:06, 29.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   9136391\n",
            "         ADJ       0.88      0.93      0.91     85589\n",
            "         ADP       1.00      0.99      0.99     81963\n",
            "         ADV       0.83      0.90      0.86     44101\n",
            "         AUX       0.85      0.89      0.87      7522\n",
            "       CCONJ       0.87      1.00      0.93     30432\n",
            "         DET       0.90      0.76      0.82     21968\n",
            "        INTJ       0.00      0.00      0.00        78\n",
            "        NOUN       0.97      0.93      0.95    214497\n",
            "         NUM       0.95      0.94      0.95     13746\n",
            "        PART       0.98      0.76      0.86     26651\n",
            "        PRON       0.85      0.92      0.88     38438\n",
            "       PROPN       0.82      0.94      0.88     32401\n",
            "       PUNCT       1.00      1.00      1.00    157989\n",
            "       SCONJ       0.86      0.64      0.73     16219\n",
            "         SYM       1.00      0.99      1.00       840\n",
            "        VERB       0.93      0.95      0.94     97670\n",
            "           X       0.93      0.58      0.72       375\n",
            "\n",
            "    accuracy                           0.99  10006870\n",
            "   macro avg       0.87      0.84      0.85  10006870\n",
            "weighted avg       0.99      0.99      0.99  10006870\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 206/205.75 [00:04<00:00, 43.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на валидации 0.018367711454629898\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   1231232\n",
            "         ADJ       0.88      0.93      0.91     11222\n",
            "         ADP       1.00      0.99      0.99     10585\n",
            "         ADV       0.83      0.90      0.86      6165\n",
            "         AUX       0.84      0.88      0.86      1106\n",
            "       CCONJ       0.87      1.00      0.93      4410\n",
            "         DET       0.89      0.73      0.80      3085\n",
            "        INTJ       0.00      0.00      0.00        11\n",
            "        NOUN       0.97      0.93      0.95     27974\n",
            "         NUM       0.94      0.93      0.94      1829\n",
            "        PART       0.99      0.76      0.86      3877\n",
            "        PRON       0.84      0.92      0.88      5598\n",
            "       PROPN       0.81      0.93      0.87      4438\n",
            "       PUNCT       1.00      1.00      1.00     22694\n",
            "       SCONJ       0.84      0.62      0.72      2258\n",
            "         SYM       1.00      0.98      0.99        53\n",
            "        VERB       0.92      0.95      0.93     13078\n",
            "           X       0.96      0.72      0.83       105\n",
            "\n",
            "    accuracy                           0.99   1349720\n",
            "   macro avg       0.87      0.84      0.85   1349720\n",
            "weighted avg       0.99      0.99      0.99   1349720\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9N3YZwDjTRs"
      },
      "source": [
        "### Предсказание частей речи на уровне предложений (с учётом контекста)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.325744Z",
          "start_time": "2019-10-29T19:46:50.139Z"
        },
        "id": "wVTpEXtSjTRt"
      },
      "source": [
        "class SentenceLevelPOSTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, labels_num, embedding_size=32, single_backbone_kwargs={}, context_backbone_kwargs={}):\n",
        "        super().__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.single_token_backbone = StackedConv1d(embedding_size, **single_backbone_kwargs)\n",
        "        self.context_backbone = StackedConv1d(embedding_size, **context_backbone_kwargs)\n",
        "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.out = nn.Conv1d(embedding_size, labels_num, 1)\n",
        "        self.labels_num = labels_num\n",
        "    \n",
        "    def forward(self, tokens):\n",
        "        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n",
        "        batch_size, max_sent_len, max_token_len = tokens.shape\n",
        "        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n",
        "        \n",
        "        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n",
        "        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n",
        "        char_features = self.single_token_backbone(char_embeddings)\n",
        "        \n",
        "        token_features_flat = self.global_pooling(char_features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n",
        "\n",
        "        token_features = token_features_flat.view(batch_size, max_sent_len, self.embedding_size)  # BatchSize x MaxSentenceLen x EmbSize\n",
        "        token_features = token_features.permute(0, 2, 1)  # BatchSize x EmbSize x MaxSentenceLen\n",
        "        context_features = self.context_backbone(token_features)  # BatchSize x EmbSize x MaxSentenceLen\n",
        "\n",
        "        logits = self.out(context_features)  # BatchSize x LabelsNum x MaxSentenceLen\n",
        "        return logits"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.326925Z",
          "start_time": "2019-10-29T19:46:50.310Z"
        },
        "id": "PDzFUGaKjTRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78430ce-8ac4-42be-e55e-3ec8625a2e48"
      },
      "source": [
        "sentence_level_model = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n",
        "                                              single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3),\n",
        "                                              context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, do_dilation=True))\n",
        "print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model.parameters()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество параметров 84882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.327888Z",
          "start_time": "2019-10-29T19:46:50.737Z"
        },
        "scrolled": false,
        "id": "Pq3WyBdnjTRu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "44c9e144-1177-4086-8a73-39b9c244d3f8"
      },
      "source": [
        "(best_val_loss,\n",
        " best_sentence_level_model) = train_eval_loop(sentence_level_model,\n",
        "                                              train_dataset,\n",
        "                                              test_dataset,\n",
        "                                              F.cross_entropy,\n",
        "                                              lr=5e-3,\n",
        "                                              epoch_n=10,\n",
        "                                              batch_size=64,\n",
        "                                              device='xla',\n",
        "                                              early_stopping_patience=5,\n",
        "                                              max_batches_per_epoch_train=500,\n",
        "                                              max_batches_per_epoch_val=100,\n",
        "                                              lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n",
        "                                                                                                                         factor=0.5,\n",
        "                                                                                                                         verbose=True))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2c603c476ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                               \u001b[0mmax_batches_per_epoch_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                               \u001b[0mmax_batches_per_epoch_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                               lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n\u001b[0m\u001b[1;32m     14\u001b[0m                                                                                                                          \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                                                                                          verbose=True))\n",
            "\u001b[0;32m/content/stepik-dl-nlp/dlnlputils/pipeline.py\u001b[0m in \u001b[0;36mtrain_eval_loop\u001b[0;34m(model, train_dataset, val_dataset, criterion, lr, epoch_n, batch_size, device, early_stopping_patience, l2_reg_alpha, max_batches_per_epoch_train, max_batches_per_epoch_val, data_loader_ctor, optimizer_ctor, lr_scheduler_ctor, shuffle_train, dataloader_workers_n)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimizer_ctor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PyTorch is not linked with support for xla devices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djOlVDs13-DW"
      },
      "source": [
        "cur_model_name "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:16.542052Z",
          "start_time": "2019-08-29T13:56:16.529110Z"
        },
        "id": "wMzISXKejTRv"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "torch.save(best_sentence_level_model.state_dict(), './stepik-dl-nlp/models/sentence_level_pos.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:16.564926Z",
          "start_time": "2019-08-29T13:56:16.544481Z"
        },
        "id": "hAHhWiEqjTRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fb8dca-6518-476e-e888-965b7e970cf1"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "sentence_level_model.load_state_dict(torch.load('./stepik-dl-nlp/models/sentence_level_pos.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xe4b6_T4PrR"
      },
      "source": [
        "del best_sentence_level_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.092139Z",
          "start_time": "2019-08-29T13:56:16.567242Z"
        },
        "id": "yoBANl9ujTRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be3d704-9158-4af1-f91f-10670f5b3f93"
      },
      "source": [
        "train_pred = predict_with_model(sentence_level_model, train_dataset)\n",
        "train_loss = F.cross_entropy(torch.tensor(train_pred),\n",
        "                             torch.tensor(train_labels))\n",
        "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n",
        "print()\n",
        "\n",
        "test_pred = predict_with_model(sentence_level_model, test_dataset)\n",
        "test_loss = F.cross_entropy(torch.tensor(test_pred),\n",
        "                            torch.tensor(test_labels))\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1526it [00:35, 42.63it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на обучении 0.010324694216251373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 3/205.75 [00:00<00:07, 28.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   9136391\n",
            "         ADJ       0.93      0.94      0.93     85589\n",
            "         ADP       1.00      1.00      1.00     81963\n",
            "         ADV       0.86      0.95      0.91     44101\n",
            "         AUX       0.90      0.90      0.90      7522\n",
            "       CCONJ       0.94      0.99      0.96     30432\n",
            "         DET       0.92      0.91      0.92     21968\n",
            "        INTJ       0.58      0.38      0.46        78\n",
            "        NOUN       0.98      0.96      0.97    214497\n",
            "         NUM       0.97      0.92      0.95     13746\n",
            "        PART       0.98      0.86      0.91     26651\n",
            "        PRON       0.92      0.94      0.93     38438\n",
            "       PROPN       0.90      0.97      0.94     32401\n",
            "       PUNCT       1.00      1.00      1.00    157989\n",
            "       SCONJ       0.91      0.84      0.88     16219\n",
            "         SYM       1.00      1.00      1.00       840\n",
            "        VERB       0.95      0.96      0.96     97670\n",
            "           X       0.97      0.52      0.68       375\n",
            "\n",
            "    accuracy                           1.00  10006870\n",
            "   macro avg       0.93      0.89      0.90  10006870\n",
            "weighted avg       1.00      1.00      1.00  10006870\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 206/205.75 [00:04<00:00, 42.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на валидации 0.011435320600867271\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   1231232\n",
            "         ADJ       0.93      0.93      0.93     11222\n",
            "         ADP       1.00      0.99      1.00     10585\n",
            "         ADV       0.86      0.95      0.90      6165\n",
            "         AUX       0.88      0.89      0.88      1106\n",
            "       CCONJ       0.94      0.99      0.96      4410\n",
            "         DET       0.91      0.90      0.90      3085\n",
            "        INTJ       0.57      0.36      0.44        11\n",
            "        NOUN       0.98      0.95      0.97     27974\n",
            "         NUM       0.96      0.90      0.93      1829\n",
            "        PART       0.98      0.86      0.92      3877\n",
            "        PRON       0.92      0.94      0.93      5598\n",
            "       PROPN       0.89      0.97      0.93      4438\n",
            "       PUNCT       1.00      1.00      1.00     22694\n",
            "       SCONJ       0.90      0.83      0.86      2258\n",
            "         SYM       1.00      1.00      1.00        53\n",
            "        VERB       0.94      0.96      0.95     13078\n",
            "           X       0.99      0.65      0.78       105\n",
            "\n",
            "    accuracy                           1.00   1349720\n",
            "   macro avg       0.92      0.89      0.90   1349720\n",
            "weighted avg       1.00      1.00      1.00   1349720\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "suGtk8Ky1Jk2",
        "outputId": "3464ff0e-d62b-453a-dafe-3d948c47e836"
      },
      "source": [
        "\n",
        "files.download( \"./stepik-dl-nlp/models/sentence_level_pos.pth\" ) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1ebbb5c2-ec51-4a4e-9031-ed40b7fd6806\", \"sentence_level_pos.pth\", 346102)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsAFAFq6jTRy"
      },
      "source": [
        "## Применение полученных теггеров и сравнение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.105418Z",
          "start_time": "2019-08-29T13:56:42.093744Z"
        },
        "id": "VUZrokx7jTRy"
      },
      "source": [
        "single_token_pos_tagger = POSTagger(single_token_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n",
        "sentence_level_pos_tagger = POSTagger(sentence_level_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.125540Z",
          "start_time": "2019-08-29T13:56:42.106771Z"
        },
        "id": "8Ce7ELP2jTRz"
      },
      "source": [
        "test_sentences = [\n",
        "    'Мама мыла раму.',\n",
        "    'Косил косой косой косой.',\n",
        "    'Глокая куздра штеко будланула бокра и куздрячит бокрёнка.',\n",
        "    'Сяпала Калуша с Калушатами по напушке.',\n",
        "    'Пирожки поставлены в печь, мама любит печь.',\n",
        "    'Ведро дало течь, вода стала течь.',\n",
        "    'Три да три, будет дырка.',\n",
        "    'Три да три, будет шесть.',\n",
        "    'Сорок сорок'\n",
        "]\n",
        "test_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.148124Z",
          "start_time": "2019-08-29T13:56:42.126930Z"
        },
        "id": "L5ohjHwWjTR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb512af5-cd97-4a37-b03f-0f0bf4f2b4b7"
      },
      "source": [
        "for sent_tokens, sent_tags in zip(test_sentences_tokenized, single_token_pos_tagger(test_sentences)):\n",
        "    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1it [00:00, 72.03it/s]                     "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "мама-NOUN мыла-VERB раму-NOUN\n",
            "\n",
            "косил-VERB косой-ADJ косой-ADJ косой-ADJ\n",
            "\n",
            "глокая-ADJ куздра-NOUN штеко-ADJ будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN\n",
            "\n",
            "сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN\n",
            "\n",
            "пирожки-NOUN поставлены-VERB в-ADP печь-VERB мама-NOUN любит-VERB печь-VERB\n",
            "\n",
            "ведро-ADV дало-VERB течь-VERB вода-NOUN стала-VERB течь-VERB\n",
            "\n",
            "три-NUM да-NOUN три-NUM будет-VERB дырка-NOUN\n",
            "\n",
            "три-NUM да-NOUN три-NUM будет-VERB шесть-NUM\n",
            "\n",
            "сорок-NOUN сорок-NOUN\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.168810Z",
          "start_time": "2019-08-29T13:56:42.149698Z"
        },
        "id": "DJQTm8gajTR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6caa60f6-3590-41d7-d956-fbc89c8836aa"
      },
      "source": [
        "for sent_tokens, sent_tags in zip(test_sentences_tokenized, sentence_level_pos_tagger(test_sentences)):\n",
        "    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1it [00:00, 80.50it/s]                     "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "мама-NOUN мыла-VERB раму-NOUN\n",
            "\n",
            "косил-VERB косой-NOUN косой-NOUN косой-NOUN\n",
            "\n",
            "глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN\n",
            "\n",
            "сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN\n",
            "\n",
            "пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-VERB\n",
            "\n",
            "ведро-NOUN дало-VERB течь-NOUN вода-NOUN стала-VERB течь-NOUN\n",
            "\n",
            "три-NUM да-CCONJ три-NUM будет-AUX дырка-NOUN\n",
            "\n",
            "три-NUM да-CCONJ три-NUM будет-AUX шесть-NUM\n",
            "\n",
            "сорок-NOUN сорок-NOUN\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWgDuruKjTR0"
      },
      "source": [
        "## Свёрточный модуль своими руками"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.193140Z",
          "start_time": "2019-08-29T13:56:42.170233Z"
        },
        "id": "3KujWJy3jTR1"
      },
      "source": [
        "class MyConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = padding\n",
        "        self.weight = nn.Parameter(torch.randn(in_channels * kernel_size, out_channels) / (in_channels * kernel_size),\n",
        "                                   requires_grad=True)\n",
        "        self.bias = nn.Parameter(torch.zeros(out_channels), requires_grad=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"x - BatchSize x InChannels x SequenceLen\"\"\"\n",
        "\n",
        "        batch_size, src_channels, sequence_len = x.shape        \n",
        "        if self.padding > 0:\n",
        "            pad = x.new_zeros(batch_size, src_channels, self.padding)\n",
        "            x = torch.cat((pad, x, pad), dim=-1)\n",
        "            sequence_len = x.shape[-1]\n",
        "\n",
        "        chunks = []\n",
        "        chunk_size = sequence_len - self.kernel_size + 1\n",
        "        for offset in range(self.kernel_size):\n",
        "            chunks.append(x[:, :, offset:offset + chunk_size])\n",
        "\n",
        "        in_features = torch.cat(chunks, dim=1)  # BatchSize x InChannels * KernelSize x ChunkSize\n",
        "        in_features = in_features.permute(0, 2, 1)  # BatchSize x ChunkSize x InChannels * KernelSize\n",
        "        out_features = torch.bmm(in_features, self.weight.unsqueeze(0).expand(batch_size, -1, -1)) + self.bias.unsqueeze(0).unsqueeze(0)\n",
        "        out_features = out_features.permute(0, 2, 1)  # BatchSize x OutChannels x ChunkSize\n",
        "        return out_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T13:56:42.210013Z",
          "start_time": "2019-08-29T13:56:42.194620Z"
        },
        "id": "eKEeQjU9jTR2"
      },
      "source": [
        "sentence_level_model_my_conv = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n",
        "                                                      single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d),\n",
        "                                                      context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d))\n",
        "print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model_my_conv.parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T14:06:00.233326Z",
          "start_time": "2019-08-29T13:56:42.211456Z"
        },
        "id": "1pF421DOjTR2"
      },
      "source": [
        "(best_val_loss,\n",
        " best_sentence_level_model_my_conv) = train_eval_loop(sentence_level_model_my_conv,\n",
        "                                                      train_dataset,\n",
        "                                                      test_dataset,\n",
        "                                                      F.cross_entropy,\n",
        "                                                      lr=5e-3,\n",
        "                                                      epoch_n=10,\n",
        "                                                      batch_size=64,\n",
        "                                                      device='cuda',\n",
        "                                                      early_stopping_patience=5,\n",
        "                                                      max_batches_per_epoch_train=500,\n",
        "                                                      max_batches_per_epoch_val=100,\n",
        "                                                      lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n",
        "                                                                                                                                 factor=0.5,\n",
        "                                                                                                                                 verbose=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-29T14:06:39.145214Z",
          "start_time": "2019-08-29T14:06:00.234936Z"
        },
        "id": "lW76zLsNjTR2"
      },
      "source": [
        "train_pred = predict_with_model(best_sentence_level_model_my_conv, train_dataset)\n",
        "train_loss = F.cross_entropy(torch.tensor(train_pred),\n",
        "                             torch.tensor(train_labels))\n",
        "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n",
        "print()\n",
        "\n",
        "test_pred = predict_with_model(best_sentence_level_model_my_conv, test_dataset)\n",
        "test_loss = F.cross_entropy(torch.tensor(test_pred),\n",
        "                            torch.tensor(test_labels))\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0TBG959npFO"
      },
      "source": [
        ""
      ]
    }
  ]
}